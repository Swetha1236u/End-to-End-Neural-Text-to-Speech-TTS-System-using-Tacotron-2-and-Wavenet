{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5977522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3645d6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r'D:/NITW_PROJECT/data/train.csv')\n",
    "val_df = pd.read_csv(r'D:/NITW_PROJECT/data/validation.csv')\n",
    "test_df = pd.read_csv(r'D:/NITW_PROJECT/data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c24b3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_tokenizer(text):\n",
    "    if isinstance(text, str):\n",
    "        return re.findall(r\"\\b\\w+\\b\", text.lower())\n",
    "    return []  \n",
    "\n",
    "word2idx = {\"<PAD>\": 0, \"<OOV>\": 1}\n",
    "idx = 2\n",
    "all_text = pd.concat([train_df[\"Headline\"], val_df[\"Headline\"], test_df[\"Headline\"]]).fillna(\"\")\n",
    "\n",
    "for text in all_text:\n",
    "    for word in simple_tokenizer(text):\n",
    "        if word not in word2idx:\n",
    "            word2idx[word] = idx\n",
    "            idx += 1\n",
    "\n",
    "def encode_text(text):\n",
    "    return [word2idx.get(word, 1) for word in simple_tokenizer(str(text))]\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(train_df[\"Language\"].astype(str))\n",
    "num_classes = len(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ace9b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeadlineDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.sequences = [torch.tensor(encode_text(text), dtype=torch.long) for text in df[\"Headline\"]]\n",
    "        self.labels = torch.tensor(label_encoder.transform(df[\"Language\"]), dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx], self.labels[idx]\n",
    "\n",
    "def collate_batch(batch):\n",
    "    sequences, labels = zip(*batch)\n",
    "    padded_seqs = pad_sequence(sequences, batch_first=True, padding_value=0)\n",
    "    return padded_seqs, torch.tensor(labels)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(HeadlineDataset(train_df), batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "test_loader = DataLoader(HeadlineDataset(test_df), batch_size=batch_size, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d24a140a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        _, (hn, _) = self.lstm(x)\n",
    "        return self.fc(hn[-1])\n",
    "\n",
    "class GRUClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.gru = nn.GRU(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        _, hn = self.gru(x)\n",
    "        return self.fc(hn[-1])\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.conv = nn.Conv1d(in_channels=embed_dim, out_channels=128, kernel_size=5)\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x).transpose(1, 2)\n",
    "        x = torch.relu(self.conv(x))\n",
    "        x = self.pool(x).squeeze(-1)\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1be78699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, num_epochs=5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in test_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            outputs = model(x_batch)\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(y_batch.numpy())\n",
    "    report = classification_report(all_labels, all_preds, target_names=label_encoder.classes_, digits=4)\n",
    "    print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a9291c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBHG(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes):\n",
    "        super(CBHG, self).__init__()\n",
    "        self.embedding = nn.Embedding(128, input_dim)\n",
    "        self.conv1 = nn.Conv1d(input_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.gru = nn.GRU(hidden_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # (B, T, D)\n",
    "        x = x.transpose(1, 2)  # (B, D, T)\n",
    "        x = self.relu(self.conv1(x))  # (B, H, T)\n",
    "        x = x.transpose(1, 2)  # (B, T, H)\n",
    "        output, _ = self.gru(x)\n",
    "        x = output[:, -1, :]  # take last time step\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "974a71ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.texts = df[\"Headline\"].tolist()\n",
    "        self.labels = df[\"label\"].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = text_to_sequence(self.texts[idx])\n",
    "        padded_seq = seq + [0]*(100 - len(seq))  # pad to 100\n",
    "        return torch.tensor(padded_seq, dtype=torch.long), torch.tensor(self.labels[idx], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b945b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "train_df[\"label\"] = label_encoder.fit_transform(train_df[\"Language\"])\n",
    "val_df[\"label\"] = label_encoder.transform(val_df[\"Language\"])\n",
    "test_df[\"label\"] = label_encoder.transform(test_df[\"Language\"])\n",
    "num_classes = len(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "129d6dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(LanguageDataset(train_df), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(LanguageDataset(val_df), batch_size=32)\n",
    "test_loader = DataLoader(LanguageDataset(test_df), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61e3fba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(dataframes):\n",
    "    vocab = set()\n",
    "    for df in dataframes:\n",
    "        df[\"Headline\"] = df[\"Headline\"].fillna(\"\")  \n",
    "        for text in df[\"Headline\"]:\n",
    "            vocab.update(set(str(text)))  \n",
    "    char2idx = {c: i + 1 for i, c in enumerate(sorted(vocab))}  \n",
    "    return char2idx\n",
    "\n",
    "char2idx = build_vocab([train_df, val_df, test_df])\n",
    "vocab_size = len(char2idx) + 1  \n",
    "\n",
    "def text_to_sequence(text, max_len=100):\n",
    "    text = str(text)  \n",
    "    seq = [char2idx.get(c, 0) for c in text]\n",
    "    if len(seq) < max_len:\n",
    "        seq += [0] * (max_len - len(seq))  \n",
    "    return seq[:max_len]  \n",
    "\n",
    "train_df[\"input\"] = train_df[\"Headline\"].apply(text_to_sequence)\n",
    "val_df[\"input\"] = val_df[\"Headline\"].apply(text_to_sequence)\n",
    "test_df[\"input\"] = test_df[\"Headline\"].apply(text_to_sequence)\n",
    "\n",
    "class CBHG(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes):\n",
    "        super(CBHG, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, input_dim, padding_idx=0)\n",
    "        self.conv1 = nn.Conv1d(input_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.gru = nn.GRU(hidden_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)        \n",
    "        x = x.transpose(1, 2)        \n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = x.transpose(1, 2)        \n",
    "        output, _ = self.gru(x)\n",
    "        x = output[:, -1, :]         \n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8cf75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 122.4745\n",
      "Epoch 2, Loss: 2.0239\n",
      "Epoch 3, Loss: 0.9899\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CBHG(input_dim=64, hidden_dim=128, num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(3):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # DEBUG: Check input range\n",
    "        max_index = inputs.max().item()\n",
    "        vocab_limit = model.embedding.num_embeddings\n",
    "        if max_index >= vocab_limit:\n",
    "            print(f\"Skipping batch - Max index {max_index} >= vocab size {vocab_limit}\")\n",
    "            continue  # Or clamp below\n",
    "\n",
    "        # Optional: Clamp to avoid crash\n",
    "        inputs = torch.clamp(inputs, max=vocab_limit - 1)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4ea69db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.9998\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     English       1.00      1.00      1.00      1473\n",
      "       Hindi       1.00      1.00      1.00      2021\n",
      "     Kannada       1.00      1.00      1.00       398\n",
      "       Tamil       1.00      1.00      1.00       479\n",
      "      Telugu       1.00      1.00      1.00       535\n",
      "\n",
      "    accuracy                           1.00      4906\n",
      "   macro avg       1.00      1.00      1.00      4906\n",
      "weighted avg       1.00      1.00      1.00      4906\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "acc = accuracy_score(all_labels, all_preds)\n",
    "report = classification_report(all_labels, all_preds, target_names=label_encoder.classes_)\n",
    "\n",
    "print(f\"\\nAccuracy: {acc:.4f}\")\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fc820f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training LSTM model...\n",
      "Performance of LSTM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     English     0.9993    0.9939    0.9966      1473\n",
      "       Hindi     1.0000    0.9792    0.9895      2021\n",
      "     Kannada     1.0000    0.9975    0.9987       398\n",
      "       Tamil     1.0000    0.9979    0.9990       479\n",
      "      Telugu     0.9097    0.9981    0.9519       535\n",
      "\n",
      "    accuracy                         0.9890      4906\n",
      "   macro avg     0.9818    0.9933    0.9871      4906\n",
      "weighted avg     0.9899    0.9890    0.9892      4906\n",
      "\n",
      "\n",
      "Training GRU model...\n",
      "Performance of GRU:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     English     1.0000    1.0000    1.0000      1473\n",
      "       Hindi     1.0000    1.0000    1.0000      2021\n",
      "     Kannada     1.0000    0.9975    0.9987       398\n",
      "       Tamil     0.9979    1.0000    0.9990       479\n",
      "      Telugu     0.9981    0.9981    0.9981       535\n",
      "\n",
      "    accuracy                         0.9996      4906\n",
      "   macro avg     0.9992    0.9991    0.9992      4906\n",
      "weighted avg     0.9996    0.9996    0.9996      4906\n",
      "\n",
      "\n",
      "Training CNN model...\n",
      "Performance of CNN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     English     1.0000    1.0000    1.0000      1473\n",
      "       Hindi     1.0000    1.0000    1.0000      2021\n",
      "     Kannada     1.0000    1.0000    1.0000       398\n",
      "       Tamil     1.0000    1.0000    1.0000       479\n",
      "      Telugu     1.0000    1.0000    1.0000       535\n",
      "\n",
      "    accuracy                         1.0000      4906\n",
      "   macro avg     1.0000    1.0000    1.0000      4906\n",
      "weighted avg     1.0000    1.0000    1.0000      4906\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word2idx)\n",
    "embed_dim = 100\n",
    "hidden_dim = 128\n",
    "\n",
    "models = {\n",
    "    \"LSTM\": LSTMClassifier(vocab_size, embed_dim, hidden_dim, num_classes),\n",
    "    \"GRU\": GRUClassifier(vocab_size, embed_dim, hidden_dim, num_classes),\n",
    "    \"CNN\": CNNClassifier(vocab_size, embed_dim, num_classes),\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name} model...\")\n",
    "    trained = train_model(model, train_loader)\n",
    "    print(f\"Performance of {name}:\")\n",
    "    evaluate_model(trained, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d56e42bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Basic Decoder class\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13190f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 128      \n",
    "hidden_dim = 64\n",
    "num_classes = 5        \n",
    "output_dim = num_classes\n",
    "vocab_size = 10000     \n",
    "embed_dim = 128\n",
    "# CNN\n",
    "cnn_encoder = CNNClassifier(input_dim, hidden_dim, output_dim)\n",
    "cnn_decoder = Decoder(hidden_dim, output_dim)\n",
    "\n",
    "# GRU\n",
    "gru_encoder = GRUClassifier(vocab_size, embed_dim, hidden_dim, output_dim)\n",
    "gru_decoder = Decoder(hidden_dim, output_dim)\n",
    "\n",
    "# LSTM\n",
    "lstm_encoder = LSTMClassifier(vocab_size, embed_dim, hidden_dim, output_dim)\n",
    "lstm_decoder = Decoder(hidden_dim, output_dim)\n",
    "\n",
    "# Save models\n",
    "torch.save(cnn_encoder.state_dict(), \"cnn_encoder.pth\")\n",
    "torch.save(cnn_decoder.state_dict(), \"cnn_decoder.pth\")\n",
    "\n",
    "torch.save(gru_encoder.state_dict(), \"gru_encoder.pth\")\n",
    "torch.save(gru_decoder.state_dict(), \"gru_decoder.pth\")\n",
    "\n",
    "torch.save(lstm_encoder.state_dict(), \"lstm_encoder.pth\")\n",
    "torch.save(lstm_decoder.state_dict(), \"lstm_decoder.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b11b9cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (linear): Linear(in_features=64, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load CNN\n",
    "cnn_encoder_loaded = CNNClassifier(input_dim, hidden_dim, output_dim)\n",
    "cnn_encoder_loaded.load_state_dict(torch.load(\"cnn_encoder.pth\"))\n",
    "cnn_encoder_loaded.eval()\n",
    "\n",
    "cnn_decoder_loaded = Decoder(hidden_dim, output_dim)\n",
    "cnn_decoder_loaded.load_state_dict(torch.load(\"cnn_decoder.pth\"))\n",
    "cnn_decoder_loaded.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1ecbbbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (linear): Linear(in_features=64, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load GRU\n",
    "gru_encoder_loaded = GRUClassifier(vocab_size, embed_dim, hidden_dim, output_dim)\n",
    "gru_encoder_loaded.load_state_dict(torch.load(\"gru_encoder.pth\"))\n",
    "gru_encoder_loaded.eval()\n",
    "\n",
    "gru_decoder_loaded = Decoder(hidden_dim, output_dim)\n",
    "gru_decoder_loaded.load_state_dict(torch.load(\"gru_decoder.pth\"))\n",
    "gru_decoder_loaded.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09524cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (linear): Linear(in_features=64, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load LSTM\n",
    "lstm_encoder_loaded = LSTMClassifier(vocab_size, embed_dim, hidden_dim, output_dim)\n",
    "lstm_encoder_loaded.load_state_dict(torch.load(\"lstm_encoder.pth\"))\n",
    "lstm_encoder_loaded.eval()\n",
    "\n",
    "lstm_decoder_loaded = Decoder(hidden_dim, output_dim)\n",
    "lstm_decoder_loaded.load_state_dict(torch.load(\"lstm_decoder.pth\"))\n",
    "lstm_decoder_loaded.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03f30f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arvin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.9.7)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import librosa\n",
    "from langdetect import detect\n",
    "from googletrans import Translator\n",
    "from gtts import gTTS\n",
    "from pydub import AudioSegment\n",
    "import pygame\n",
    "import os\n",
    "from scipy.io.wavfile import write as wav_write\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "606a958d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Text to sequence ---\n",
    "def text_to_sequence(text):\n",
    "    return [ord(c) for c in text.lower() if c.isalnum() or c == ' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b326345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Encoder Models ---\n",
    "class LSTMEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "    def forward(self, x):\n",
    "        output, _ = self.lstm(x)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c4643ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CBHG(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, K=16):\n",
    "        super(CBHG, self).__init__()\n",
    "        self.conv1d_banks = nn.ModuleList(\n",
    "            [nn.Conv1d(input_dim, hidden_dim, kernel_size=k, padding=k // 2) for k in range(1, K+1)]\n",
    "        )\n",
    "        self.batch_norms = nn.ModuleList(\n",
    "            [nn.BatchNorm1d(hidden_dim) for _ in range(K)]\n",
    "        )\n",
    "        self.max_pool = nn.MaxPool1d(kernel_size=2, stride=1, padding=1)\n",
    "        self.projection1 = nn.Conv1d(K * hidden_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.projection2 = nn.Conv1d(hidden_dim, input_dim, kernel_size=3, padding=1)\n",
    "        self.highway = nn.Linear(input_dim, hidden_dim)\n",
    "        self.rnn = nn.GRU(hidden_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2) \n",
    "        conv_outputs = []\n",
    "        for conv, bn in zip(self.conv1d_banks, self.batch_norms):\n",
    "            c = F.relu(bn(conv(x)))\n",
    "            conv_outputs.append(c)\n",
    "        x = torch.cat(conv_outputs, dim=1)\n",
    "        x = self.max_pool(x)[:, :, :-1]  \n",
    "        x = F.relu(self.projection1(x))\n",
    "        x = self.projection2(x)\n",
    "        x = x.transpose(1, 2)  \n",
    "        highway = self.highway(x)\n",
    "        out, _ = self.rnn(highway)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70456b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, batch_first=True)\n",
    "    def forward(self, x):\n",
    "        output, _ = self.gru(x)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a99e47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, hidden_dim, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.conv(x)\n",
    "        return x.transpose(1, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15ff1747",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def hmm_synthesis(text):\n",
    "    print(\"Generating speech using HMM model (simulated)\")\n",
    "    duration = max(len(text) * 80, 4000)\n",
    "    waveform = np.sin(np.linspace(0, duration * np.pi / 100, duration))\n",
    "    return waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12fd1f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gtts_speak(text, lang_code='en'):\n",
    "    import time\n",
    "    import os\n",
    "    from gtts import gTTS\n",
    "\n",
    "    filename = f\"gtts_output_{int(time.time())}.mp3\"\n",
    "    try:\n",
    "        tts = gTTS(text=text, lang=lang_code)\n",
    "        tts.save(filename)\n",
    "        print(f\"gTTS saved as {filename}\")\n",
    "        os.system(f'start {filename}')  # For Windows\n",
    "    except PermissionError as e:\n",
    "        print(f\"Permission error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to generate gTTS audio: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c466a279",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Language & Model Mapping ---\n",
    "translator = Translator()\n",
    "LANG_MODEL_MAP = {\n",
    "    'en': 'lstm',\n",
    "    'hi': 'gru',\n",
    "    'te': 'cnn',\n",
    "    'ta': 'cnn',\n",
    "    'kn': 'hmm'\n",
    "}\n",
    "GTTS_LANG_CODES = {\n",
    "    'en': 'en',\n",
    "    'hi': 'hi',\n",
    "    'te': 'te',\n",
    "    'ta': 'ta',\n",
    "    'kn': 'kn'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60a2a546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected input language: en\n",
      "Translated (en → hi): नमस्ते, आप कैसे हैं\n",
      "Selected model: GRU\n",
      "Audio saved as 'output_1749779997.wav'\n",
      "Also generating gTTS speech for clarity:\n",
      "gTTS saved as gtts_output_1749779998.mp3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Main Function ---\n",
    "def multilingual_tts_interactive():\n",
    "    num_classes=1\n",
    "    input_text = input(\"Enter a sentence: \").strip()\n",
    "    if not input_text:\n",
    "        print(\"No input provided.\")\n",
    "        return\n",
    "\n",
    "    target_lang = input(\"Enter target language code (en, hi, te, ta, kn): \").strip().lower()\n",
    "    if target_lang not in LANG_MODEL_MAP:\n",
    "        print(\"Invalid language code.\")\n",
    "        return\n",
    "\n",
    "    device = torch.device(\"cpu\")\n",
    "    detected_lang = detect(input_text)\n",
    "    print(f\"Detected input language: {detected_lang}\")\n",
    "\n",
    "    try:\n",
    "        translated = translator.translate(input_text, src=detected_lang, dest=target_lang).text\n",
    "        print(f\"Translated ({detected_lang} → {target_lang}): {translated}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Translation failed: {e}\")\n",
    "        translated = input_text\n",
    "\n",
    "    model_choice = LANG_MODEL_MAP[target_lang]\n",
    "    print(f\"Selected model: {model_choice.upper()}\")\n",
    "\n",
    "    if model_choice == 'hmm':\n",
    "        waveform = hmm_synthesis(translated)\n",
    "    else:\n",
    "        seq = text_to_sequence(translated)\n",
    "        if len(seq) < 10:\n",
    "            print(\"Input text too short, padding\")\n",
    "            seq += [32] * (10 - len(seq))\n",
    "        input_tensor = torch.tensor(seq, dtype=torch.float32).unsqueeze(0).unsqueeze(-1).to(device)\n",
    "\n",
    "        hidden_dim = 64        \n",
    "        output_dim = 80       \n",
    "\n",
    "        hidden_dim = 64\n",
    "        output_dim = 80  \n",
    "\n",
    "        if model_choice == 'lstm':\n",
    "            encoder = LSTMEncoder(input_dim=1, hidden_dim=hidden_dim).to(device)\n",
    "        elif model_choice == 'gru':\n",
    "            encoder = GRUEncoder(input_dim=1, hidden_dim=hidden_dim).to(device)\n",
    "        elif model_choice == 'cnn':\n",
    "            encoder = CNNEncoder(input_dim=1, hidden_dim=hidden_dim).to(device)\n",
    "        else:\n",
    "            print(\"Unsupported model\")\n",
    "            return\n",
    "\n",
    "        decoder = Decoder(hidden_dim, output_dim).to(device)\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            encoded = encoder(input_tensor)\n",
    "            mel = decoder(encoded).squeeze(0).transpose(0, 1)\n",
    "            mel_np = mel.cpu().numpy()\n",
    "            mel_np = np.clip(mel_np, a_min=1e-5, a_max=None)\n",
    "            waveform = librosa.feature.inverse.griffinlim(mel_np, n_iter=60)\n",
    "\n",
    "    if waveform is not None and np.max(np.abs(waveform)) > 0:\n",
    "        waveform = waveform / np.max(np.abs(waveform))\n",
    "        import time\n",
    "        output_file = f\"output_{int(time.time())}.wav\"\n",
    "        sf.write(output_file, waveform, 22050)\n",
    "\n",
    "        print(f\"Audio saved as '{output_file}'\")\n",
    "\n",
    "        pygame.mixer.init()\n",
    "        pygame.mixer.music.load(output_file)\n",
    "\n",
    "        while pygame.mixer.music.get_busy():\n",
    "            pass\n",
    "    else:\n",
    "        print(\"No valid waveform generated.\")\n",
    "\n",
    "    print(\"Also generating gTTS speech for clarity:\")\n",
    "    gtts_speak(translated, GTTS_LANG_CODES.get(target_lang, 'en'))\n",
    "\n",
    "# --- Run ---\n",
    "if __name__ == \"__main__\":\n",
    "    multilingual_tts_interactive()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bd7a39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
